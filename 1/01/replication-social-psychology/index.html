<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <title>
        Replication in Psychology - JM Barbone
      </title>
    <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport"
    content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  
  <meta name="theme-color" content="#000000" />
  
  <meta http-equiv="window-target" content="_top" />
  
  
  <meta name="description" content="IntroductionWhat is the “Replication Crisis”?Large-scale Replication AttemptsThe Open Science CollaborationThe “Many Labs” ProjectCase StudiesThe Marshmallow testViolence in video gamesFuture Directions in Social PsychologyConcluding RemarksReferencesAdvanced Social Psychology.A project on contemporary topics in Social Psychology.I managed to weasel around the requirements (social isn’t quite my field) and present and write on research methodologies, specifically on the “replication crisis” and how it relates to Social Psychology." />
  <meta name="generator" content="Hugo 0.69.2 with theme pure" />
  <title>Replication in Psychology - JM Barbone</title>
  
  
  <link rel="stylesheet" href="/css/style.min.c4bc7071f132c964c2116bca53b392933f377e5ca7b7051ed245187c621a2d3e.css">
  
  <link rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/9.15.10/styles/github.min.css" async>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.css" async>
  <meta property="og:title" content="Replication in Psychology" />
<meta property="og:description" content="IntroductionWhat is the “Replication Crisis”?Large-scale Replication AttemptsThe Open Science CollaborationThe “Many Labs” ProjectCase StudiesThe Marshmallow testViolence in video gamesFuture Directions in Social PsychologyConcluding RemarksReferencesAdvanced Social Psychology.A project on contemporary topics in Social Psychology.I managed to weasel around the requirements (social isn’t quite my field) and present and write on research methodologies, specifically on the “replication crisis” and how it relates to Social Psychology." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/1/01/replication-social-psychology/" />

<meta itemprop="name" content="Replication in Psychology">
<meta itemprop="description" content="IntroductionWhat is the “Replication Crisis”?Large-scale Replication AttemptsThe Open Science CollaborationThe “Many Labs” ProjectCase StudiesThe Marshmallow testViolence in video gamesFuture Directions in Social PsychologyConcluding RemarksReferencesAdvanced Social Psychology.A project on contemporary topics in Social Psychology.I managed to weasel around the requirements (social isn’t quite my field) and present and write on research methodologies, specifically on the “replication crisis” and how it relates to Social Psychology.">

<meta itemprop="wordCount" content="4496">



<meta itemprop="keywords" content="psychology,replication," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Replication in Psychology"/>
<meta name="twitter:description" content="IntroductionWhat is the “Replication Crisis”?Large-scale Replication AttemptsThe Open Science CollaborationThe “Many Labs” ProjectCase StudiesThe Marshmallow testViolence in video gamesFuture Directions in Social PsychologyConcluding RemarksReferencesAdvanced Social Psychology.A project on contemporary topics in Social Psychology.I managed to weasel around the requirements (social isn’t quite my field) and present and write on research methodologies, specifically on the “replication crisis” and how it relates to Social Psychology."/>

  <!--[if lte IE 9]>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
    <![endif]-->

  <!--[if lt IE 9]>
      <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
    <![endif]-->

</head>
  </head>

  
  

  <body class="main-center theme-grey" itemscope itemtype="http://schema.org/WebPage"><header class="header" itemscope itemtype="http://schema.org/WPHeader">
    <div class="slimContent">
      <div class="navbar-header">
        <div class="profile-block text-center">
          <a id="avatar" href="https://github.com/jmbarbone" target="_blank">
            <img class="img-circle img-rotate" src="/myAvatar.svg" width="200" height="200">
          </a>
          <h2 id="name" class="hidden-xs hidden-sm">Jordan Mark Barbone, M.A.</h2>
          <h3 id="title" class="hidden-xs hidden-sm hidden-md">R &amp; Psychology</h3>
          <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i>King of Prussia, PA USA</small>
        </div><div class="search" id="search-form-wrap">
    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="Search" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i
                        class="icon icon-search"></i></button>
            </span>
        </div>
        <div class="ins-search">
            <div class="ins-search-mask"></div>
            <div class="ins-search-container">
                <div class="ins-input-wrapper">
                    <input type="text" class="ins-search-input" placeholder="Type something..."
                        x-webkit-speech />
                    <button type="button" class="close ins-close ins-selectable" data-dismiss="modal"
                        aria-label="Close"><span aria-hidden="true">×</span></button>
                </div>
                <div class="ins-section-wrapper">
                    <div class="ins-section-container"></div>
                </div>
            </div>
        </div>
    </form>
</div>
        <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
      </div>
      <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
        <ul class="nav navbar-nav main-nav">
            <li class="menu-item menu-item-home">
                <a href="/">
                    <i class="icon icon-home-fill"></i>
                  <span class="menu-title">Home</span>
                </a>
            </li>
            <li class="menu-item menu-item-about">
                <a href="/homepage/about/">
                    <i class="icon icon-cup-fill"></i>
                  <span class="menu-title">About</span>
                </a>
            </li>
            <li class="menu-item menu-item-cvresume">
                <a href="/homepage/cv-resume/">
                    <i class="icon icon-profile"></i>
                  <span class="menu-title">CV Resume</span>
                </a>
            </li>
            <li class="menu-item menu-item-anthology">
                <a href="/homepage/anthology/">
                    <i class="icon icon-book-shelf"></i>
                  <span class="menu-title">Anthology</span>
                </a>
            </li>
            <li class="menu-item menu-item-archives">
                <a href="/posts/">
                    <i class="icon icon-archives-fill"></i>
                  <span class="menu-title">Archives</span>
                </a>
            </li>
            <li class="menu-item menu-item-categories">
                <a href="/categories/">
                    <i class="icon icon-folder"></i>
                  <span class="menu-title">Categories</span>
                </a>
            </li>
            <li class="menu-item menu-item-tags">
                <a href="/tags/">
                    <i class="icon icon-tags"></i>
                  <span class="menu-title">Tags</span>
                </a>
            </li>
        </ul>
      </nav>
    </div>
  </header>

<aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title"> Categories</h3>
    <div class="widget-body">
        <ul class="category-list">
            <li class="category-list-item"><a href="/categories/paper/" class="category-list-link">paper</a><span class="category-list-count">2</span></li>
            <li class="category-list-item"><a href="/categories/presentation/" class="category-list-link">presentation</a><span class="category-list-count">1</span></li>
            <li class="category-list-item"><a href="/categories/r-code/" class="category-list-link">r-code</a><span class="category-list-count">3</span></li>
        </ul>
    </div>
</div>
      <div class="widget">
    <h3 class="widget-title"> Tags</h3>
    <div class="widget-body">
        <ul class="tag-list">
            
            
            <li class="tag-list-item"><a href="/tags/datavis/" class="tag-list-link">datavis</a><span
                    class="tag-list-count">1</span></li>
            
            
            <li class="tag-list-item"><a href="/tags/factor-analysis/" class="tag-list-link">factor-analysis</a><span
                    class="tag-list-count">1</span></li>
            
            
            <li class="tag-list-item"><a href="/tags/pgkproc/" class="tag-list-link">pgkproc</a><span
                    class="tag-list-count">1</span></li>
            
            
            <li class="tag-list-item"><a href="/tags/pkgcaret/" class="tag-list-link">pkgcaret</a><span
                    class="tag-list-count">1</span></li>
            
            
            <li class="tag-list-item"><a href="/tags/psychology/" class="tag-list-link">psychology</a><span
                    class="tag-list-count">3</span></li>
            
            
            <li class="tag-list-item"><a href="/tags/psychometrics/" class="tag-list-link">psychometrics</a><span
                    class="tag-list-count">1</span></li>
            
            
            <li class="tag-list-item"><a href="/tags/r/" class="tag-list-link">r</a><span
                    class="tag-list-count">2</span></li>
            
            
            <li class="tag-list-item"><a href="/tags/replication/" class="tag-list-link">replication</a><span
                    class="tag-list-count">1</span></li>
            
            
            <li class="tag-list-item"><a href="/tags/roc/" class="tag-list-link">roc</a><span
                    class="tag-list-count">1</span></li>
            
        </ul>

    </div>
</div>
      
<div class="widget">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget-body">
        <ul class="recent-post-list list-unstyled no-thumbnail">
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/2020/04/dunning-kruger/" class="title">Dunning Kruger Effect</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2020-04-26 00:00:00 &#43;0000 UTC" itemprop="datePublished">2020-04-26</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/2020/04/its-alive/" class="title">It&#39;s Alive</a>
                    </p>
                    <p class="item-date">
                        <time datetime="2020-04-26 00:00:00 &#43;0000 UTC" itemprop="datePublished">2020-04-26</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/1/01/psychometrics-class-paper/" class="title">Psychometrics (class) scale development</a>
                    </p>
                    <p class="item-date">
                        <time datetime="0001-01-01 00:00:00 &#43;0000 UTC" itemprop="datePublished">0001-01-01</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/1/01/roc/" class="title">Receiver operator characteristic curve</a>
                    </p>
                    <p class="item-date">
                        <time datetime="0001-01-01 00:00:00 &#43;0000 UTC" itemprop="datePublished">0001-01-01</time>
                    </p>
                </div>
            </li>
            <li>
                <div class="item-inner">
                    <p class="item-title">
                        <a href="/1/01/replication-social-psychology/" class="title">Replication in Psychology</a>
                    </p>
                    <p class="item-date">
                        <time datetime="0001-01-01 00:00:00 &#43;0000 UTC" itemprop="datePublished">0001-01-01</time>
                    </p>
                </div>
            </li>
        </ul>
    </div>
</div>
  </div>
</aside>

    
    
<aside class="sidebar sidebar-toc collapse" id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    <h4 class="toc-title">Catalogue</h4>
    <nav id="toc" class="js-toc toc">

    </nav>
  </div>
</aside>
<main class="main" role="main"><div class="content">
  <article id="-" class="article article-type-" itemscope
    itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      <h1 itemprop="name">
  <a
    class="article-title"
    href="/1/01/replication-social-psychology/"
    >Replication in Psychology</a
  >
</h1>

      <div class="article-meta">
        <span class="article-category">
  <i class="icon icon-folder"></i>&nbsp;
  <a class="article-category-link" href="/categories/paper/"> paper </a>
  <a class="article-category-link" href="/categories/presentation/"> presentation </a>
</span>  
  <span class="article-tag">
    <i class="icon icon-tags"></i>&nbsp;
    <a class="article-tag-link" href="/tags/psychology/"> psychology </a>
    <a class="article-tag-link" href="/tags/replication/"> replication </a>
  </span>

        <span class="post-comment"><i class="icon icon-comment"></i>&nbsp;<a href="/1/01/replication-social-psychology/#comments"
            class="article-comment-link">Comments</a></span>
		<span class="post-wordcount hidden-xs" itemprop="wordCount">Word Count: 4496words</span>
		<span class="post-readcount hidden-xs" itemprop="timeRequired">Read Count: 22minutes </span>
      </div>
    </div>
    <div class="article-entry marked-body js-toc-content" itemprop="articleBody">
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#what-is-the-replication-crisis">What is the “Replication Crisis”?</a></li>
<li><a href="#large-scale-replication-attempts">Large-scale Replication Attempts</a>
<ul>
<li><a href="#the-open-science-collaboration">The Open Science Collaboration</a></li>
<li><a href="#the-many-labs-project">The “Many Labs” Project</a></li>
</ul></li>
<li><a href="#case-studies">Case Studies</a>
<ul>
<li><a href="#the-marshmallow-test">The Marshmallow test</a></li>
<li><a href="#violence-in-video-games">Violence in video games</a></li>
</ul></li>
<li><a href="#future-directions-in-social-psychology">Future Directions in Social Psychology</a></li>
<li><a href="#concluding-remarks">Concluding Remarks</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<p>Advanced Social Psychology.
A project on contemporary topics in Social Psychology.
I managed to weasel around the requirements (social isn’t quite my field) and present and write on research methodologies, specifically on the “replication crisis” and how it relates to Social Psychology.</p>
<p>The xaringan presentation shown below.
You can find all the files and the paper in my poorly created <a href="https://jmbarbone.github.io/psy609">psy609 repository</a>.</p>
<center>
<iframe src="https://jmbarbone.github.io/psy609/fdsp_presentation#1" width="75%" style="height: 50vh;">
</iframe>
</center>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>In the 17th century Robert Boyle’s reported success in observing anomalous suspension of water with his sophisticated air pump was put to question. These findings were difficult to replicate due to the instruments cost and complexity. Christiaan Huygens was able to produce a similar effect with his own device but was met with the same reaction. A debate over validating claims and differentiating between “thought experiments” and actual experiments was birthed. The Royal Society was not satisfied until in 1663 when Huygens was invited to England and able to successfully replicate this phenomenon <span class="citation">(Shapin 1984)</span>.</p>
<p>A growing sense of the necessity of replicability and establishing facts that could be observed by others came from these events. Today, to publish in well-respected journals, researchers must describe the methods of their study or experiment well enough for the reader to be able to successfully implement the same procedures and assumingly reach similar conclusions. Yet without formal testing, these might be more akin to the thought experiments Boyle discussed. Replicability is easily – and perhaps suitably – stressed through the words of the others, such as Braude <span class="citation">(2002)</span> who comments, “only experiments whose results can be repeated are considered genuine and reliable” and that this can be used as a “demarcation criterion between science and non-science”.</p>
</div>
<div id="what-is-the-replication-crisis" class="section level1">
<h1>What is the “Replication Crisis”?</h1>
<p>Sanja Srivastava maintains a blog, “The Hardest Science”, with insights he holds as a professor and researcher in social psychology. His blog is named in part to retaliate against the conceptualization of science existing on a continuum, from the soft (e.g., psychology, sociology) to the hard (e.g., physics) <span class="citation">(Srivastava 2009)</span>. He argues that each field is equal to the other, scientifically, as they all seek to answer inquiries by applying logic and reasoning to evidence, although the issues undertaken vary. Psychology focuses on understanding complex systems and tries to find patterns and reason to behavior. In this way, the issues psychology faces are more difficult to answer clearly. Therefore, we may want to discontinue describing psychology as a “soft science” and adopt “the hardest science”. This will be an important idea to maintain as issues with psychological replication are put forth and when attention is focused on social psychology and while understanding that these problems are not just unique to this field but may span across the whole of science <span class="citation">(Ioannidis 2005; Sterne and Smith 2001)</span>.</p>
<p>One estimate places the rate of replication in 100 psychology journals at 1.07% of publications <span class="citation">(Makel, Plucker, and Hegarty 2012)</span>, with rates steadily increasing towards 2.5% in the 2010s. It is easy to consider why this is the case. Conducting a replication can be a tedious, time consuming and resource draining process. The replicating researchers may have to go to additional lengths to understand the methodology of the original researchers to ensure a set-up as similar to the original as possible. Even if the replication is a success, there is a general consensus that journals favor novelty and positive finding.</p>
<p>Makel and colleagues <span class="citation">(2012)</span> also note that the median number of citations for replication articles was estimated at 17 which was lower than the median rate for the original study at 64.5. But 17 citations for an article is still a decent accomplishment; only 3 of the 100 journals examined had 5-year impact factors above 17. This suggests that replication articles are generally well-received by researchers. Publishing companies may want to focus on new research findings but metrics like these may providing a convincing argument that that accepting replication articles might contribute to higher impact factors and attention to journals. Submitting a replication to the journal of the original article may also provide an additional incentive as a reference to the replication would likely be paired with a reference to the original work.</p>
<p>Replication in psychology is a rare yet rewarded occurrence. However, it is worthwhile to really delve into the necessity of replications. After all, calls and requests for greater replication may require large, consuming endeavors. Psychology has been functioning with a small number of replications for quite some time, so to question the necessity is reasonable.</p>
<p>Pashler and Harris <span class="citation">(2012)</span> examined three arguments against the magnitude of the replication crisis. The first argument puts forth the standard 5% likelihood of acceptance of a false null hypothesis and 80% likelihood of rejecting a false null hypothesis. These may seem like safe thresholds, but the false positive rate of published articles is likely much higher than these would insinuate. We can crudely calculate the probability that a positive result is false finding (<span class="math inline">\(\alpha^1\)</span>) by dividing the proportion of false positives (<span class="math inline">\(P_\alpha\)</span>) by the sum of the proportion of false positives and the proportion of correct rejections (<span class="math inline">\(P_\beta\)</span>); i.e., <span class="math inline">\(\alpha^1 = \frac{P_\alpha}{P_\alpha + P_\beta}\)</span>. Assuming a prior probability of a true effect is 10%, and given a Type I error level of .05, <span class="math inline">\(P_\alpha = .05 * (1 - 10) = .045\)</span>. Given a power level of .80, we would find that <span class="math inline">\(\alpha^1 = .045 / (.045 * .80) = .36\)</span>. We can then conclude that given the standard statistical assumptions, and a prior probability of 10%, the likelihood that a finding is false is 36%. This is a generous assumption that does not take into account other factors that could lead to biased false positives.</p>
<p>In his brazenly titled article, “Why most published research findings are false”, Ioannidis <span class="citation">(2005)</span> provides a more expansive review of the probability of false positive or exaggerated articles. His formulae include variables for researcher bias and the number of teams involved in a particular field. Using these methods, Iaonnidis identifies six corrollaries to estimated false positive rates. Inversely related are sample sizes and effect sizes. Positively related are number of tests (with less pre-selection of tests); design or methodology flexibility; financial or interest in publishing the finding; and the number teams involved in a particular area. His last corollary seems at first counterintuitive. Ioannidis proposes that the “hotter” the area of research the more pressure researchers have to disseminate their “impressive” findings. Ioannidis comes to the conclusion that, given all these factors, the majority of research – across all fields – are likely to be false or exaggerated reports of effects.</p>
<p>The second argument Pashler and Harris <span class="citation">(2012)</span> tackle is the notion that despite a lack of <em>direct</em> replication, <em>conceptual</em> replications are more frequent and test not just the validity of the original research but also the generalizability. The authors echo concerns from Ioannidis <span class="citation">(2005)</span> that published conceptual replications represent the favored “interesting” findings. If conceptual replications did provide a more rigorous testing of a hypothesis it might reason that the rate of failure here would be higher than it is. Of the estimate 1.07% of publications; direct replications constituting only 14% of these <span class="citation">(Makel, Plucker, and Hegarty 2012)</span>. The publication rate for failed direct replications (14.6%) is nearly twice that of failed conceptual replications (7.5%). This difference in positive findings could be result of the difficulty of estimating the likelihood that a false finding is due to the original hypothesis being incorrect, that the theory does not generalize to the specific difference, or that the replication was not designed or executed well enough <span class="citation">(Earp and Trafimow 2015)</span>.</p>
<p>Cohen <span class="citation">(1994)</span> provides insight that can be applied in parallel to this the conceptual replication through criticizing thresholds of null hypothesis significance testing (NHST) and outlining a few misconceptions and misuses of statistical analyses. Often the <em>null hypothesis</em> is interpreted as finding no effect rather than the hypothesis which is to be nulled. These tests are not just to compare whether there exists an effect but that levels of effect ought to be compared as well. To highlight a misuse, Cohen states the absurdity of testing rater reliability: that is, testing whichever computed statistic against the <em>null hypothesis</em> that there exists no reliability between or amongst raters; even with a small sample these results would look significant. This fundamental misuse of NHST may then lead researchers to believe that because they have successfully reject a null hypothesis – rather than nullified a previous hypothesis – that their theory must be true <span class="citation">(Meehl 1990)</span>. Greater understanding of null hypothesis testing may aid in the design and interpretation of direct and conceptual replications.</p>
<p>Science, we like to think, is self-correcting. Pashler and Harris <span class="citation">(2012)</span> challenge this argument last. They note their quick Google Scholar search for replication failures showed that the median replication attempt delay was 4 years<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> with 10% of replications occurring longer than 10 years. This is could be taken as a good sign that researchers are quick to scrutinize research with their own attempts. However, Pasher and Harris contend that this may simply represent the “faddish” nature of psychological research and that research which has failed to replicate may have also failed to maintain the herd’s interest. Older, possibly less contemporarily interesting research, should also be provided the service of scrutiny and re-examination.</p>
<p>When 1,500 scientists were surveyed on comments and rates of replications, roughly half of those in psychology (approximately 54 respondents) reported having failed to reproduce their own work or someone else’s work <span class="citation">(Baker 2016)</span>. Approximately 55% of respondents all failed to replicate their own work and more than 70% failed to replicate another’s; only 16% of these respondents successfully published a failure to reproduce. Self-correction, through publication of failed replications, does not seem to be that great of an argument if these results are all lost to the dreaded file drawer – or, increasingly appropriate, forgotten flash drive.</p>
<p>Replications, although well-received by researchers, are a bit of a rarity in the literature. However, there also appears to be growing interest as the rates of replications are increasing and as groups are formed to take on this problem.</p>
</div>
<div id="large-scale-replication-attempts" class="section level1">
<h1>Large-scale Replication Attempts</h1>
<p>The task of reproducibility testing can be performed with single attempts and thorough examination of specific results as they were reported in the original article. Possibly a more effective means of garnering more attention is large-scale replications attempts which tests a great many hypotheses once more or multiple testing of a select few hypotheses. With such a great endeavor, researchers are leveraging cooperation across multiple research sites and labs. Two examples of large-scale replication attempts are described below.</p>
<div id="the-open-science-collaboration" class="section level2">
<h2>The Open Science Collaboration</h2>
<p>The Open Science Collaboration (OSC) of the Center for Open Science (COS) has promoted interest in replication studies and called for setting standards for replication attempts <span class="citation">(Open Science Collaboration 2012)</span>. The OSC selected 100 contemporary studies across three journals in psychology and reported the results of their replications in what would become a highly cited and publicized article. Of these 100, 93 originally reported significant findings<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>, but only 36 replication findings reached the same conclusion. When separating by discipline, the rate of success for cognitive studies was greater than social (21/42 and 14/55, respectively<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>). This demonstrates a much lower proportion of false positives than 36% of positive findings <span class="citation">(Pashler and Harris 2012)</span> and provides support for models suggesting that the bulk of published research is false <span class="citation">(Ioannidis 2005)</span>. Original studies that reported greater effect sizes and more significant findings were more likely to be replicated than those with smaller effects and less significance, in line with suggestions from Ioannidis <span class="citation">(Ioannidis 2005)</span> and presumed correlates of false positives.</p>
<p>The COS has made clear possible issues with their findings. They acknowledge that there is no single standard for determining the success of a replication and thus report on several measures that may be taken into account <span class="citation">(Open Science Collaboration 2012, 2015)</span>. Their selection of articles was not entirely random either, and they acknowledge that there are inherently greater challenges in replicating some psychological research that may rely on a specific population or dependent on an historical event. There is further criticism regarding some changes made in the replications which might invalidate their status as direct replications <span class="citation">(Gilbert et al. 2016)</span>.</p>
</div>
<div id="the-many-labs-project" class="section level2">
<h2>The “Many Labs” Project</h2>
<p>In a different method, the “Many Labs” project attempted 36 replications of 13 studies, with the main purpose to understand the variability of replication findings <span class="citation">(Klein et al. 2014)</span>. This method, although more demanding than the OSC’s attempts, provides much a more comprehensive evaluation of findings reported by studies. Variations in effect sizes compared against original reports and <em>p</em> values from each replication were taken into consideration of replication success. Of the 13 articles tested, 10 of them showed clear indications of successful replications. The articles tested were chosen for their simplicity, ability to be completed both in person or online, and the general level of procedural replicability – similar to the criteria from the OSC.</p>
<p>Klein and colleagues <span class="citation">(2014)</span> also tested the variation of effect sizes found across each lab by computing an intra-class correlation and using an ANOVA across each lab and between online or in-person testing. These showed an acceptable level of agreement (ICC = .75) across study sites and little impact of study location (all <span class="math inline">\(\eta^2_P\)</span> &lt; .023). The only impact which may have been noted was from better base knowledge in the anchoring tests<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>.</p>
</div>
</div>
<div id="case-studies" class="section level1">
<h1>Case Studies</h1>
<p>Although these may represent singular instances of less than ideal research, attributing the concepts and ideas above may help provide an example of their effects. Two case studies have been provided below. The first of this will examine a well-known study and some of the limitations in understanding confounding variables. The second takes a look at a divisive field and the possibly of bias and poor data handling.</p>
<div id="the-marshmallow-test" class="section level2">
<h2>The Marshmallow test</h2>
<p>Walter Mischel’s now famous Stanford marshmallow studies have generally found correlates between the delay of gratification to better life outcomes <span class="citation">(Mischel, Shoda, and Rodriguez 1989; Ayduk et al. 2000)</span>. A recent conceptual replication identified some criticism of the original studies <span class="citation">(Watts, Duncan, and Quan 2018)</span>. Namely, that the original children tested were from a highly selected sample in the Stanford University community and the studies also failed to account for possible confounds such as mother’s education and home environment. The sample retained for longitudinal studies were also much lower than their original experiment (35-89 and over 600, respectively). In their replication, Watts, Duncan, and Quan utilized data from the National Institute of Child Health and Human Development (NICHD) Study of Early Child Care and Youth Development (SECCYD). Data included information on a delayed gratification test and behavioral outcomes at age 15. These children were all born of mothers who did not have or complete a college education. Only this group was examined due to concerns with truncation of gratification delay measures from children born to mothers who completed college and because the examined population is more appropriate and of greater interest to policy-makers of developmental interventions.</p>
<p>In their analysis, Watts and colleagues were able to show a replication of achievement scores at age 15, although this effect was smaller than in the original studies. They were not able to find significance with delayed gratification and behavioral measures. The significant results they found were also moderated by variables such as child background, home environment, and early cognitive skills – so much so that the interaction of delayed gratification being insignificant. Albeit this is one study that has dampened the relationship of self-control to later life outcomes, it is an important one. Displayed here is the concern of controlling for variables that may not have been of interested to the original researchers. Although the initial and follow-up findings have shown significance and the track record appears sound, revisiting the study itself highlights concerns. Replications like these are necessary for understanding how even ubiquitous findings that seem unanimous in the literature may require additional scrutiny.</p>
</div>
<div id="violence-in-video-games" class="section level2">
<h2>Violence in video games</h2>
<p>There exists a contentious forum between researchers in the field of media whether violent media – specifically video games – contribute to violent acts by individuals. A meta-analysis <span class="citation">(Anderson and Bushman 2001)</span> concluded that violent video games increase aggression, physiological arousal, and aggression-related thoughts and feelings – with small but positive relationships. Yet another meta-analysis <span class="citation">(Ferguson 2007)</span> found that video games were not linked to aggression after controlling for publication bias. This second meta-analysis also reported on improvement on visuospatial cognition. Here, too, there was an issue with publication bias – but even when adjusting for this, the improvement effect was still significant.</p>
<p>Now, with conflicting meta-analyses, researchers may be stuck <em>inter canem et lupum</em> when reasoning out how to interpret these findings. There also exists another bias, other than publication, from either side: the first meta-analysis was presented in part by Brad Bushman – a researcher known in this niche for finding ways media and video games influence aggressive behaviors. The second was published by Christopher John Ferguson, a researcher who quite frequently challenges these views.</p>
<p>Along with these claims, this area of social psychology has been subjected to a complicated scandal centering around Brad Bushman and a doctoral student of his, Jodie Whitaker. In April 2013, Whitaker and Bushman published their article, <em>“Boom, Headshot!”: Effect of video game play and controller type on firing aim and accuracy</em> online in the journal <em>Communication Research</em> <span class="citation">(2012)</span>. A data request made because of concerns over appropriateness of statistical analyses initiated a long process of correspondences and a research investigation<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>. Four years later, the article was retracted <span class="citation">(Communication Research Editors 2017)</span> and Jodie Whitaker’s PhD was revoked by Ohio State University. The senior author was dismissed of all allegations and was able to publish a replication of this study shortly after <span class="citation">(Bushman 2018)</span>. Not all original effects were replicated, including the main findings of controller type. Further, reported in the replication were small effects, significance levels – in most cases – just under .05, and an increase in sample size. This replication appears to be a partial success with outcomes that may suggest a chance finding.</p>
</div>
</div>
<div id="future-directions-in-social-psychology" class="section level1">
<h1>Future Directions in Social Psychology</h1>
<p>It is clear that replication is an issue to be resolved. The COS has considered ways in which to examine the results of replications <span class="citation">(Open Science Collaboration 2012, 2015)</span>. In a similar vein, there need to be a further discussion on how to go about replications. Designing a replication study may not be as easy as exactly reproducing the same methods from the investigative study <span class="citation">(Maxwell, Lau, and Howard 2015)</span>, particularly around sample size and estimated power, to the point where we may have to be just as critical of replication articles as the original investigative article.</p>
<p>Replicability is also not well addressed in psychology education and training. We are taught to think about how our study, our experiment is unique and what it offers. What’s our twist on the topic? How are we differentiating this work from the work of others? All in attempts to find your work in a reputable academic journal. The publish or perish attitudes that may be conveyed at some institutions would lead to prioritization of new ideas than the confirmation of new and current ones.</p>
<p>Begeley and Ioannidis <span class="citation">(2015)</span> have curated a list of ways in which we can help correct for the lack of replications and the overall goodness of science. Among these are emphasizing greater statistical and experimental methodology knowledge; providing open access to data for examination and analytic replication; using more meta-analytic techniques for establishing general findings in areas of research; lobbying journals to solicit replication bids; and pushing institutional responsibility, possibly to the point of requiring some level of open access or replicability. A suggested cultural change is to consider, more greatly, the quality of research and judge academics and other researchers on their reproducibility, openness and sharing. This may help switch the needed focus towards confirmation rather than simply discovery.</p>
</div>
<div id="concluding-remarks" class="section level1">
<h1>Concluding Remarks</h1>
<p>The lack of direct replication should undoubtedly be an issue in psychology – especially in the social field – but that that does not mean that all past work is questionable. Assuming that older published works are wrong would create even more issues with meta-analytic methods <span class="citation">(Makel, Plucker, and Hegarty 2012)</span>. As mentioned earlier, <em>indirect</em> and <em>conceptual</em> replications occur often. For now, these will have to do to demonstrate that phenomenon of past research is sound and replicable.</p>
<p>We should leave with a few notes of caution and tips. Research reproduced outside the original laboratory or collaborators aids more in demonstrating reproducibility than multiple articles from the same institution. Although most published replications have at least one of the original authors <span class="citation">(Makel, Plucker, and Hegarty 2012)</span> Failure to replicate does not mean that the original effect is invalid. As the COS has suggested, the issue may even be with the attempt the replicate and methodological differences that were overlooked or unnoticed <span class="citation">(Open Science Collaboration 2012)</span>. There may exists some concepts and theories that are downright wrong and invalid but bad research continues to push these to publishers. Inveresly, a good idea may have gone unnoticed because the first experiment happened to fail. But we ought not to disqualify any large portion of psychology simply due to concerns about reproducibility. Early findings may be a little grim, but those tested may have been chosen for simplicity in design and not necessarily to challenge well-cited work. In fact, Daniel Kahneman’s framing <span class="citation">(Tversky and Kahneman 1981)</span> and anchoring effects <span class="citation">(Jacowitz and Kahneman 1995)</span> were found to be even stronger in replication attempts <span class="citation">(Klein et al. 2014)</span>.</p>
<p>Two schools of thought, extreme in opposition, can be called upon when reacting to the overall threat of the “replication crisis”. To take the <em>pessimistic meta-inductionism</em> approach would be to begin throwing out research on the grounds that the previous works have been falsified, disproved, or <em>un-proven</em>. It would take that if studies and theories, which were one or still are held as truth are incorrect, why should be not dismiss the bulk of what we know? The <em>epistemic optimist</em> would assert that through rigorous scientific process, what we know now is true, or the approximately true. Yes, some long-held concepts will be dismantled, and others held in a possibly state of limbo of acceptance, but we cannot simply disregard everything and start at square one, again.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references hanging-indent">
<div id="ref-anderson2001effects">
<p>Anderson, Craig A, and Brad J Bushman. 2001. “Effects of Violent Video Games on Aggressive Behavior, Aggressive Cognition, Aggressive Affect, Physiological Arousal, and Prosocial Behavior: A Meta-Analytic Review of the Scientific Literature.” <em>Psychological Science</em> 12 (5): 353–59. <a href="https://doi.org/10.1111/1467-9280.00366">https://doi.org/10.1111/1467-9280.00366</a>.</p>
</div>
<div id="ref-ayduk2000regulating">
<p>Ayduk, Ozlem, Rodolfo Mendoza-Denton, Walter Mischel, Geraldine Downey, Philip K Peake, and Monica Rodriguez. 2000. “Regulating the Interpersonal Self: Strategic Self-Regulation for Coping with Rejection Sensitivity.” <em>Journal of Personality and Social Psychology</em> 79 (5): 776. <a href="https://doi.org/10.1037/0022-3514.79.5.776">https://doi.org/10.1037/0022-3514.79.5.776</a>.</p>
</div>
<div id="ref-baker2016scientists">
<p>Baker, Monya. 2016. “1,500 Scientists Lift the Lid on Reproducibility.” <em>Nature News</em> 533 (7604): 452. <a href="https://doi.org/10.1038/533452a">https://doi.org/10.1038/533452a</a>.</p>
</div>
<div id="ref-begley2015reproducibility">
<p>Begley, C Glenn, and John PA Ioannidis. 2015. “Reproducibility in Science: Improving the Standard for Basic and Preclinical Research.” <em>Circulation Research</em> 116 (1): 116–26. <a href="https://doi.org/10.1161/CIRCRESAHA.114.303819">https://doi.org/10.1161/CIRCRESAHA.114.303819</a>.</p>
</div>
<div id="ref-braude2002esp">
<p>Braude, Stephen E. 2002. <em>ESP and Psychokinesis: A Philosophical Examination</em>. Universal-Publishers.</p>
</div>
<div id="ref-bushman2018boom">
<p>Bushman, Brad J. 2018. ““Boom, Headshot!”: Violent First-Person Shooter (FPS) Video Games That Reward Headshots Train Individuals to Aim for the Head When Shooting a Realistic Firearm.” <em>Aggressive Behavior</em> 45 (1): 33–41. <a href="https://doi.org/10.1002/ab.21794">https://doi.org/10.1002/ab.21794</a>.</p>
</div>
<div id="ref-cohen1994earth">
<p>Cohen, Jacob. 1994. “The Earth Is Round (P0.6em<span class="math inline">\(\less\)</span>0.6em.05).” <em>American Psychologist</em> 49 (12): 997–1003. <a href="https://doi.org/10.1037/0003-066X.49.12.997">https://doi.org/10.1037/0003-066X.49.12.997</a>.</p>
</div>
<div id="ref-whitaker2017retraction">
<p>Communication Research Editors. 2017. “Retraction Notice.” <em>Communication Research</em> 44 (1): 144–44. <a href="https://doi.org/10.1177/0093650217690274">https://doi.org/10.1177/0093650217690274</a>.</p>
</div>
<div id="ref-earp2015replication">
<p>Earp, Brian D, and David Trafimow. 2015. “Replication, Falsification, and the Crisis of Confidence in Social Psychology.” <em>Frontiers in Psychology</em> 6: 621. <a href="https://doi.org/10.3389/fpsyg.2015.00621">https://doi.org/10.3389/fpsyg.2015.00621</a>.</p>
</div>
<div id="ref-ferguson2007good">
<p>Ferguson, Christopher John. 2007. “The Good, the Bad and the Ugly: A Meta-Analytic Review of Positive and Negative Effects of Violent Video Games.” <em>Psychiatric Quarterly</em> 78 (4): 309–16. <a href="https://doi.org/10.1007/s11126-007-9056-9">https://doi.org/10.1007/s11126-007-9056-9</a>.</p>
</div>
<div id="ref-gilbert2016comment">
<p>Gilbert, Daniel T, Gary King, Stephen Pettigrew, and Timothy D Wilson. 2016. “Comment on ‘Estimating the Reproducibility of Psychological Science’.” <em>Science</em> 351 (6277): 1037–7. <a href="https://doi.org/10.1126/science.aad7243">https://doi.org/10.1126/science.aad7243</a>.</p>
</div>
<div id="ref-ioannidis2005why">
<p>Ioannidis, John PA. 2005. “Why Most Published Research Findings Are False.” <em>PLoS Medicine</em> 2 (8): e124. <a href="https://doi.org/10.1371/journal.pmed.0020124">https://doi.org/10.1371/journal.pmed.0020124</a>.</p>
</div>
<div id="ref-jacowitz1995measures">
<p>Jacowitz, Karen E, and Daniel Kahneman. 1995. “Measures of Anchoring in Estimation Tasks.” <em>Personality and Social Psychology Bulletin</em> 21 (11): 1161–6. <a href="https://doi.org/10.1177/01461672952111004">https://doi.org/10.1177/01461672952111004</a>.</p>
</div>
<div id="ref-klein2014investigating">
<p>Klein, Richard A., Kate A. Ratliff, Michelangelo Vianello, Reginald B. Adams, Štěpán Bahnı́k, Michael J. Bernstein, Konrad Bocian, et al. 2014. “Investigating Variation in Replicability a "Many Labs" Replication Project.” <em>Social Psychology</em> 45 (3): 142–52. <a href="https://doi.org/10.1027/1864-9335/a000178">https://doi.org/10.1027/1864-9335/a000178</a>.</p>
</div>
<div id="ref-makel2012replications">
<p>Makel, Matthew C, Jonathan A Plucker, and Boyd Hegarty. 2012. “Replications in Psychology Research: How Often Do They Really Occur?” <em>Perspectives on Psychological Science</em> 7 (6): 537–42. <a href="https://doi.org/10.1177/1745691612460688">https://doi.org/10.1177/1745691612460688</a>.</p>
</div>
<div id="ref-maxwell2015suffering">
<p>Maxwell, Scott E, Michael Y Lau, and George S Howard. 2015. “Is Psychology Suffering from a Replication Crisis? What Does ‘Failure to Replicate’ Really Mean?” <em>American Psychologist</em> 70 (6): 487. <a href="https://doi.org/10.1037/a0039400">https://doi.org/10.1037/a0039400</a>.</p>
</div>
<div id="ref-meehl1990summaries">
<p>Meehl, Paul E. 1990. “Why Summaries of Research on Psychological Theories Are Often Uninterpretable.” <em>Psychological Reports</em> 66 (1): 195–244. <a href="https://doi.org/10.2466/pr0.1990.66.1.195">https://doi.org/10.2466/pr0.1990.66.1.195</a>.</p>
</div>
<div id="ref-mischel1989delay">
<p>Mischel, Walter, Yuichi Shoda, and Monica I Rodriguez. 1989. “Delay of Gratification in Children.” <em>Science</em> 244 (4907): 933–38. <a href="https://doi.org/10.1126/science.2658056">https://doi.org/10.1126/science.2658056</a>.</p>
</div>
<div id="ref-open2012open">
<p>Open Science Collaboration. 2012. “An Open, Large-Scale, Collaborative Effort to Estimate the Reproducibility of Psychological Science.” <em>Perspectives on Psychological Science</em> 7 (6): 657–60. <a href="https://doi.org/10.1177/1745691612462588">https://doi.org/10.1177/1745691612462588</a>.</p>
</div>
<div id="ref-open2015estimating">
<p>———. 2015. “Estimating the Reproducibility of Psychological Science.” <em>Science</em> 349 (6251). <a href="https://doi.org/10.1126/science.aac4716">https://doi.org/10.1126/science.aac4716</a>.</p>
</div>
<div id="ref-pashler2012replicability">
<p>Pashler, Harold, and Christine R Harris. 2012. “Is the Replicability Crisis Overblown? Three Arguments Examined.” <em>Perspectives on Psychological Science</em> 7 (6): 531–36. <a href="https://doi.org/10.1177/1745691612463401">https://doi.org/10.1177/1745691612463401</a>.</p>
</div>
<div id="ref-shapin1984pump">
<p>Shapin, Steven. 1984. “Pump and Circumstance: Robert Boyle’s Literary Technology.” <em>Social Studies of Science</em> 14 (4): 481–520. <a href="https://doi.org/10.1177/030631284014004001">https://doi.org/10.1177/030631284014004001</a>.</p>
</div>
<div id="ref-srivastava2009making">
<p>Srivastava, Sanjay. 2009. “Making Progress in the Hardest Science.” <a href="https://thehardestscience.com/2009/03/14/making-progress-in-the-hardest-science/">https://thehardestscience.com/2009/03/14/making-progress-in-the-hardest-science/</a>.</p>
</div>
<div id="ref-sterne2001sifting">
<p>Sterne, Jonathan AC, and George Davey Smith. 2001. “Sifting the Evidence—What’s Wrong with Significance Tests?” <em>Physical Therapy</em> 81 (8): 1464–9. <a href="https://doi.org/10.1093/ptj/81.8.1464">https://doi.org/10.1093/ptj/81.8.1464</a>.</p>
</div>
<div id="ref-tversky1981framing">
<p>Tversky, Amos, and Daniel Kahneman. 1981. “The Framing of Decisions and the Psychology of Choice.” <em>Science</em> 211 (4481): 453–58. <a href="https://doi.org/10.1126/science.7455683">https://doi.org/10.1126/science.7455683</a>.</p>
</div>
<div id="ref-watts2018revisiting">
<p>Watts, Tyler W., Greg J. Duncan, and Haonan Quan. 2018. “Revisiting the Marshmallow Test: A Conceptual Replication Investigating Links Between Early Delay of Gratification and Later Outcomes.” <em>Psychological Science</em> 29 (7): 1159–77. <a href="https://doi.org/10.1177/0956797618761661">https://doi.org/10.1177/0956797618761661</a>.</p>
</div>
<div id="ref-whitacker2012boom">
<p>Whitaker, Jodi L., and Brad J. Bushman. 2012. “RETRACTED: ‘Boom, Headshot!’: Effect of Video Game Play and Controller Type on Firing Aim and Accuracy.” <em>Communication Research</em> 41 (7): 879–91. <a href="https://doi.org/10.1177/0093650212446622">https://doi.org/10.1177/0093650212446622</a>.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I attempted a similar search by looking at the first 15 articles to which I had immediate access. The median and approximate mean was 6 years – although 11 of the replication articles were published in the 80s or 90s.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Significant effects here being defined by a reported <em>p</em> of less than .05.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>This reported only on the 97 original articles with reported significance and reported on the those with p &lt; .05 in the original direction.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Included examples were the height of Mt Everest, distance to New York City, NY, and the population of Chicago, IL.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>A timeline of the events and correspondences, as well as records of files and reports exchanged, is available here: <a href="http://www.malte-elson.com/headshot" class="uri">http://www.malte-elson.com/headshot</a><a href="#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

    </div>
    <div class="article-footer">
<blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    <li class="post-copyright-link hidden-xs">
      <strong>Permalink: </strong>
      <a href="/1/01/replication-social-psychology/" title="Replication in Psychology" target="_blank" rel="external">/1/01/replication-social-psychology/</a>
    </li>
    <li class="post-copyright-license">
      <strong>License：</strong><a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN</a>
    </li>
  </ul>
</blockquote>

<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://github.com/jmbarbone" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/myAvatar.svg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://github.com/jmbarbone" target="_blank"><span class="text-dark">Jordan Mark Barbone, M.A.</span><small class="ml-1x">R &amp; Psychology</small></a></h3>
        <div>Just trying to make it</div>
      </div>
    </figure>
  </div>
</div>
    </div>
  </article>
<section id="comments">
</section>

</div><nav class="bar bar-footer clearfix" data-stick-bottom>
    <div class="bar-inner">
        <ul class="pager pull-left">
            <li class="next">
                <a href="/1/01/roc/"
                    title="Receiver operator characteristic curve"><span>Newer&nbsp;&nbsp;</span><i
                        class="icon icon-angle-right" aria-hidden="true"></i></a>
            </li>
            
            <li class="toggle-toc">
                <a class="toggle-btn collapsed" data-toggle="collapse" href="#collapseToc" aria-expanded="false"
                    title="Catalogue" role="button">
                    <span>[&nbsp;</span><span>Catalogue</span>
                    <i class="text-collapsed icon icon-anchor"></i>
                    <i class="text-in icon icon-close"></i>
                    <span>]</span>
                </a>
            </li>
        </ul>
        <div class="bar-right">
            <div class="share-component" data-sites="facebook,twitter,linkedin"
                data-mobile-sites="facebook,twitter,linkedin"></div>
        </div>
    </div>
</nav>

</main><footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
<ul class="social-links">
    <li><a href="https://github.com/jmbarbone" target="_blank" title="github" data-toggle=tooltip data-placement=top >
            <i class="icon icon-github"></i></a></li>
    <li><a href="https://scholar.google.com/citations?authuser=1&amp;user=R6GyUVYAAAAJ" target="_blank" title="googlescholar" data-toggle=tooltip data-placement=top >
            <i class="icon icon-googlescholar"></i></a></li>
    <li><a href="https://linkedin.com/in/jmbarbone" target="_blank" title="linkedin" data-toggle=tooltip data-placement=top >
            <i class="icon icon-linkedin"></i></a></li>
    <li><a href="https://researchgate.net/profile/Jordan_Barbone" target="_blank" title="researchgate" data-toggle=tooltip data-placement=top >
            <i class="icon icon-researchgate"></i></a></li>
    <li><a href="/index.xml" target="_blank" title="rss" data-toggle=tooltip data-placement=top >
            <i class="icon icon-rss"></i></a></li>
</ul>
  <div class="copyright">
    &copy;2020  -
    2020
    <div class="publishby">
        Theme by <a href="https://github.com/xiaoheiAh" target="_blank"> xiaoheiAh </a>base on<a href="https://github.com/xiaoheiAh/hugo-theme-pure" target="_blank"> pure</a>.
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
            showMathMenu: false, //disables context menu
            tex2jax: {
            inlineMath: [ ['$','$'], ['\\(','\\)'] ]
           }
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>
<script>
    window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>
<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/highlight.min.js"></script>
<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/languages/python.min.js" defer></script>
<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/languages/javascript.min.js" defer></script>
<script type="text/javascript" src="https://cdn.staticfile.org/highlight.js/9.15.10/languages/r.min.js" defer></script><script>
    hljs.configure({
        tabReplace: '    ', 
        classPrefix: ''     
        
    })
    hljs.initHighlightingOnLoad();
</script>
<script src="/js/application.min.bdeb64b910570b6c41badc6a05b7afb0c8ad9efd8525de3c7257d59e786326a3.js"></script>
<script src="/js/plugin.min.51ff8c7317566f82259170fa36e09c4493adc9b9378b427a01ad3f017ebac7dd.js"></script>

<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            ROOT_URL: '\/',
            CONTENT_URL: '\/\/searchindex.json ',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script type="text/javascript" src="/js/insight.min.a343cd9a5a7698336b28ef3a7c16a3a1b1d2d5fb17dc8ed04022bbe08cc5459073a15bdafa3a8a58cdd56080784bdd69fa70b1ae8597565c799c57ed00f0e120.js" defer></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.4.2/tocbot.min.js"></script>
<script>
    tocbot.init({
        
        tocSelector: '.js-toc',
        
        contentSelector: '.js-toc-content',
        
        headingSelector: 'h1, h2, h3',
        
        hasInnerContainers: true,
    });
</script>


  </body>
</html>
