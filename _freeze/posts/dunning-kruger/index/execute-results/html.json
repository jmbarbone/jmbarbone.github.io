{
  "hash": "7a6217f413e04ab3d495258c0caf78f8",
  "result": {
    "markdown": "---\ntitle: \"Dunning-Kruger effect\"\nsubtitle: \"A case of itself?\"\ndate: \"2020-05-05\"\nupdated: \"2022-07-09\"\nbibliography: \"references.bib\"\ncategories: [\"R\", \"psychology\", \"datavis\"]\n---\n\n\n> Note: I originally wrote this in February 2019.\nAlso, don't hate me for putting some links to Wikipedia, you were going to go there anyway.\nThis isn't a research paper.\n\n## Introduction\n\nIn my Organization Psychology graduate class at West Chester University, one of our assigned readings (among others) for our week on emotions and moods was [@sheldon2014emotionally].\nThis article focused on another finding relating to the [Dunning-Kruger effect](https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect) in the workplace.\nThis time, in a task related to [emotional intelligence (EI)](https://en.wikipedia.org/wiki/Emotional_intelligence).\nDuring the time I remember vaguely hearing somewhere I will never recall, some mathematical issues relating to this well-known psychological phenomenon mentioned in many introductory text books.\n\nThe Dunning-Kruger effect is founding on the concept that an individual that lacks expertise will be more confident in their abilities than they really are, or overestimate their performance on a task.\nYet experts may underestimate their own performance or abilities or be more accurate in their estimations.\nOne thing we can derive from this is possibly that those with lower skill will overestimate their abilities while those more skilled will underestimate their abilities.\n\nThe following is in direct relation to an article by [@sheldon2014emotionally].\nThey report a significant relationship between an individual's actual performance and the difference between their perceived ability and actual performance in three conditions ($r_1 = -0.83$, $p_1 < .001$; $r_2 = -0.87$, $p_2 < .001$; $r_3 = -0.84$, $p_3 < .001$).\n\nThey also used these two graphs to representing their findings:\n\n![_Figure 1_.  Overestimation of emotional intelligence (left panel) and performance on the Mayer-Salovey-Caruso Emotional Intelligence Test (MSCEIT; right panel) as a function of actual performance on the MSCEIT](sheldon2014emotionally_figure1.png)\n\nWe'll go through and understand why this can be misleading and how to replicate the Dunning-Kruger effect **with random data**.\nYes, _random data_.\nData that are random.\n\n## Set up\n\nSo let's place with some data and see what we get.\nFirst, let's setup our `.Rmd` file and choose a specific randomization seed so we can come back to our results [@adams1979hitchhikers]:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\n\noptions(tidyverse.quiet = TRUE) ## silences warnings\nlibrary(tidyverse)\nlibrary(mark)                   ## percentile_rank() | github.com/jmbarbone/mark\n#> \n#> Attaching package: 'mark'\n#> The following object is masked from 'package:purrr':\n#> \n#>     none\nlibrary(broom)                  ## tidying statistical outputs into tables\ntheme_set(theme_minimal())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nf_nbins <- function(x, n = 6) {\n  dplyr::ntile(x, n) / n\n}\n```\n:::\n\n\n\n## Random data\n\nWe'll start by creating a data frame with two vectors of independent, random data.\nThese will be our randomly assigned percentile ranks of `actual` and `estimate`'d performance.\n\nTo clarify, the calculation of [percentile rank](https://github.com/jmbarbone/mark/blob/main/R/percentile-rank.R) is as follows:\n\n\n$$\\text{PR}_i = \\frac{c_\\ell + 0.5 f_i}{N} \\times 100%$$\n\n\nWhere $c_\\ell$ is the count of scores lower than the score of interest, $f_i$ is the frequency of the score of interest, and $N$ is the total number of scores.\nWith this formula, our percentile ranks will always be 0 < $PR_i$ < 100.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrandom_data <- \n  tibble(\n    actual = rnorm(1000),\n    estimate = rnorm(1000)\n  ) %>% \n  mutate(across(everything(), percentile_rank))\n\nrandom_data\n#> # A tibble: 1,000 × 2\n#>    actual estimate\n#>     <dbl>    <dbl>\n#>  1  0.920   0.988 \n#>  2  0.292   0.704 \n#>  3  0.656   0.846 \n#>  4  0.738   0.646 \n#>  5  0.670   0.150 \n#>  6  0.462   0.274 \n#>  7  0.946   0.576 \n#>  8  0.464   0.0005\n#>  9  0.980   0.198 \n#> 10  0.480   0.798 \n#> # … with 990 more rows\n```\n:::\n\n\nWe also want to bin our data together just like in the article.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbins <- \n  random_data %>% \n  mutate(\n    difference = estimate - actual,\n    bin = f_nbins(actual, 5)\n  ) %>% \n  group_by(bin) %>% \n  summarise(\n    n = n(),\n    mean = mean(difference)\n  )\n\nbins\n#> # A tibble: 5 × 3\n#>     bin     n    mean\n#>   <dbl> <int>   <dbl>\n#> 1   0.2   200  0.398 \n#> 2   0.4   200  0.208 \n#> 3   0.6   200  0.0120\n#> 4   0.8   200 -0.215 \n#> 5   1     200 -0.402\n```\n:::\n\n\nNow we'll plot the data and take a look at this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(random_data, aes(x = actual, y = estimate - actual)) +\n  geom_point(alpha = .2) +\n  geom_smooth(formula = \"y ~ x\", method = lm, se = FALSE, col = \"red\") +\n  geom_point(data = bins, aes(x = bin, y = mean), col = \"blue\", shape = 1, size = 5) +\n  geom_line( data = bins, aes(x = bin, y = mean), col = \"blue\", size = 1) +\n  geom_hline(yintercept = 0, linetype = 2) +\n  labs(\n    title = \"Independent random samples of 'Actual' and 'Estimate' performance\",\n    x = \"'Actual' performance (Percentile Rank)\",\n    y = \"Percentile Overestimation\\n(estimate - actual)\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/random-plot-1.png){width=672}\n:::\n:::\n\n\nAlready we're seeing a trend very similar to that reported in the article.\nWhat we also notice is that there are bounds to the overestimation value as a factor of the individual's actual performance.\nAn individual that performs at the 99th percentile cannot overestimate their own performance (but can be accurate) - much like an individual in the lower percentiles would unlikely underestimate.\nThese is additionally worse by the use of a score derived in reference to others.\n\n\n\n\n\n\n\n## Adjusting random data\n\nSo now we're going to take some data and use some rough estimates for means.\nWe'll use the results from the study of interest.\nSo simplicity, I'll just use the rough means of the n, means, and sd reported from the first two studies.\n\n![](sheldon2014emotionally_table1.png)\n\nWe'll shape our normal distributions around the values found in the paper.\nThese values, to be clear, are the percentile ranks either estimated from the participant or the actual ones as they compare to percentile ranking among U.S. adults in EI.\nAs such, we won't need to use the `percentile_rank()` again.\n\n<!-- What? SD of a uniform is like .28 -- what are these numbers? -->\n<!-- Are they reporting out on the average percentile ranks? -->\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadj_random <- tibble(\n  actual     = rnorm(161, 42.2, sd = 25.1) / 100,\n  estimate   = rnorm(161, 77.5, sd = 13.1) / 100,\n  difference = actual - estimate,\n  bin        = f_nbins(actual, 5)\n)\n\nadj_bins <- \n  adj_random  %>% \n  group_by(bin) %>% \n  summarise(\n    n = n(),\n    mean = mean(difference)\n  )\n```\n:::\n\n\nLet's also take a look at the correlations we have.\nAs expected, we have no correlation with random data.\nThe article reported correlations of `.20` and `.19` between estimated and actual performance.\nClearly, people are not that great at estimating their own performance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor.test(~ actual + estimate, data = adj_random)\n#> \n#> \tPearson's product-moment correlation\n#> \n#> data:  actual and estimate\n#> t = 1.3, df = 159, p-value = 0.1955\n#> alternative hypothesis: true correlation is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.05296245  0.25321085\n#> sample estimates:\n#>       cor \n#> 0.1025525\n```\n:::\n\n\nWell, no surprise that that our correlations are a weaker and less statistically significant, we're using random data after all.\n\nNow we're going to run a correlation on the `actual` scores and the difference between the `estimated` and `actual` performance. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor_test_result <- cor.test(~ actual + difference, data = adj_random)\ncor_test_result\n#> \n#> \tPearson's product-moment correlation\n#> \n#> data:  actual and difference\n#> t = 21.717, df = 159, p-value < 2.2e-16\n#> alternative hypothesis: true correlation is not equal to 0\n#> 95 percent confidence interval:\n#>  0.8197724 0.8991906\n#> sample estimates:\n#>       cor \n#> 0.8647931\n```\n:::\n\n\nNow, look at that.\nWe have found an even more significant, negative correlation.\nThis is roughly similar to those reported by in this article.\nThis is with data that has absolutely no relationship between the two variables, as we have justed established.\n\nSo why is this?\n\n## Plotting adjusted random data\n\nLet's graph out our results with a little more care this time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(adj_random, aes(x = actual, y = difference)) +\n  geom_hline(yintercept = 0, linetype = 2) +\n  geom_point(alpha = .1) +\n  geom_smooth(\n    formula = \"y ~ x\",\n    method = \"lm\",\n    se = FALSE,\n    col = \"red\"\n  ) +\n  geom_point(\n    data = adj_bins,\n    aes(x = bin, y = mean),\n    col = \"blue\",\n    shape = 1,\n    size = 5\n  ) +\n  geom_line(\n    data = adj_bins,\n    aes(x = bin, y = mean),\n    col = \"blue\",\n    size = 1\n  ) +\n  labs(\n    title = \"Randomly generated differences in 'actual' vs 'estimated' performance\",\n    subtitle = \"Estimate: M = 75, SD = 15; Actual: M = 5, SD = 25\",\n    x = \"Actual performance\",\n    y = \"Estimated - Actual performance\"\n  ) +\n  annotate(\n    geom = \"text\",\n    label = glue::glue_data(cor_test_result, \"r = {round(estimate, 3)}, p = {format(p.value)}\"),\n    x = .65,\n    y = .50,\n    hjust = \"left\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/adj-plot-1.png){width=672}\n:::\n:::\n\n\n## More random data\n\nSo what if we repeated this several times?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrandom_helper <- function(x) {\n  set.seed(42 + x)\n  tibble(\n    actual   = rnorm(161, 42.2, sd = 25.1) / 100,\n    estimate = rnorm(161, 77.5, sd = 13.1) / 100,\n  ) %>%\n    mutate(across(everything(), percentile_rank))\n}\n\nsev_random <- \n  as.list(seq(100)) %>% \n  map(random_helper) %>% \n  bind_rows(.id = \"id\") %>% \n  mutate(id = as.numeric(id))\n\nsev_bins <- sev_random %>% \n  group_by(id) %>% \n  mutate(\n    difference = estimate - actual,\n    bin = f_nbins(actual, 5) \n  ) %>% \n  group_by(id, bin) %>% \n  summarise(\n    n = n(),\n    mean_est = mean(estimate),\n    mean_diff = mean(difference)\n  )\n\nggplot(sev_bins, aes(x = bin, y = mean_est, col = factor(id))) +\n  geom_point() +\n  geom_line() +\n  # scale_color_discrete(name = \"Randomization\") +\n  scale_color_discrete(guide = FALSE) +\n  scale_y_continuous(limits = c(0, 1)) + \n  labs(x = \"Actual\", y = \"Estimate\")\n#> Warning: It is deprecated to specify `guide = FALSE` to remove a guide. Please\n#> use `guide = \"none\"` instead.\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nSo what if we actually run a correlation on these numbers?\nWe'll create a nested function and install the `broom` package to help tidy up our results.   \n\n\n::: {.cell}\n\n```{.r .cell-code}\nrun_correlations <- function(x, item_x, item_y) {\n  corr_helper <- function(x, item_x, item_y) {\n    formula <- str_c(\"~\", item_x, \"+\", item_y, sep = \" \")\n    cor.test(eval(parse(text = formula)), data = x)\n  }\n  \n  x %>% \n    nest(data = -id) %>% \n    mutate(\n      corr = map(data, corr_helper, item_x, item_y),\n      tidy = map(corr, tidy)\n    ) %>% \n    unnest(tidy) %>% \n    select(where(negate(is.list)))\n}\n\n(x <- run_correlations(sev_random, \"actual\", \"estimate\") %>% arrange(p.value))\n#> # A tibble: 100 × 9\n#>       id estimate statistic p.value parameter conf.low conf.high method  alter…¹\n#>    <dbl>    <dbl>     <dbl>   <dbl>     <int>    <dbl>     <dbl> <chr>   <chr>  \n#>  1    35   -0.207     -2.67 0.00830       159 -0.351    -0.0545  Pearso… two.si…\n#>  2    24    0.185      2.37 0.0188        159  0.0312    0.330   Pearso… two.si…\n#>  3    99    0.170      2.17 0.0314        159  0.0154    0.316   Pearso… two.si…\n#>  4    22   -0.164     -2.09 0.0379        159 -0.311    -0.00930 Pearso… two.si…\n#>  5    90   -0.159     -2.03 0.0443        159 -0.306    -0.00417 Pearso… two.si…\n#>  6     6    0.148      1.89 0.0610        159 -0.00685   0.296   Pearso… two.si…\n#>  7     9    0.141      1.79 0.0747        159 -0.0141    0.289   Pearso… two.si…\n#>  8    97    0.133      1.70 0.0914        159 -0.0216    0.282   Pearso… two.si…\n#>  9    51   -0.127     -1.61 0.109         159 -0.276     0.0285  Pearso… two.si…\n#> 10    89   -0.124     -1.57 0.118         159 -0.273     0.0316  Pearso… two.si…\n#> # … with 90 more rows, and abbreviated variable name ¹​alternative\n(y <- run_correlations(sev_bins, \"bin\", \"mean_est\") %>% arrange(p.value))\n#> # A tibble: 100 × 9\n#> # Groups:   id [100]\n#>       id estimate statistic p.value parameter conf.low conf.high method  alter…¹\n#>    <dbl>    <dbl>     <dbl>   <dbl>     <int>    <dbl>     <dbl> <chr>   <chr>  \n#>  1    99    0.936      4.62  0.0191         3    0.312     0.996 Pearso… two.si…\n#>  2    35   -0.936     -4.61  0.0192         3   -0.996    -0.309 Pearso… two.si…\n#>  3    28   -0.907     -3.72  0.0337         3   -0.994    -0.122 Pearso… two.si…\n#>  4    41    0.845      2.74  0.0715         3   -0.146     0.990 Pearso… two.si…\n#>  5    68    0.836      2.64  0.0780         3   -0.177     0.989 Pearso… two.si…\n#>  6     5   -0.804     -2.34  0.101          3   -0.987     0.269 Pearso… two.si…\n#>  7     6    0.796      2.28  0.107          3   -0.290     0.986 Pearso… two.si…\n#>  8    10    0.786      2.20  0.115          3   -0.314     0.985 Pearso… two.si…\n#>  9    89   -0.761     -2.03  0.135          3   -0.983     0.369 Pearso… two.si…\n#> 10    13   -0.758     -2.01  0.138          3   -0.983     0.376 Pearso… two.si…\n#> # … with 90 more rows, and abbreviated variable name ¹​alternative\n\nmean(x$p.value < .05)\n#> [1] 0.05\nmean(y$p.value < .05)\n#> [1] 0.03\n```\n:::\n\n\n\nWhen we calculated a correlation with the mean estimates we actually got a significant result from a few of our runs.\nIf fact, about 5% or less are statistically significant...\nLet's pull that one out to look at it again.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsignificant_ids <- x %>% filter(p.value < .05) %>% pull(id) %>% as.character()\ntemp <- sev_bins %>% filter(id %in% significant_ids)\n\nsev_random %>% \n  filter(id %in% significant_ids) %>% \n  ggplot(aes(x = actual, y = estimate, group = factor(id), color = factor(id))) +\n  geom_point(alpha = .2) +\n  geom_point(data = temp, aes(x = bin, y = mean_est)) +\n  geom_line(data = temp, aes(x = bin, y = mean_est))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nSo there you have it.\nA successful replication of this 'effect' with random data.\n\nBut why is this?\nThis is partly because individuals at the lowest quantiles will have a greater likelihood of over-estimating their performance and those at the highest quantiles will underestimate.\nAn individual that performs at the 99th quantile will have almost no choice but to estimate their performance to be below that of reality (see also [@nuhfer2016random]). \nThis seems to be further worsened by the bound nature of the scores.\nWere these scores and estimates to be something not bound in such a way (for instance the speed in which an individual could complete an assessment) examning the relationship between actual and estimate performance could yield more valid results.\nThese graphical representations and analyses should be cautioned as they are not very meaningful to understanding their effects.\n\n# References\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}